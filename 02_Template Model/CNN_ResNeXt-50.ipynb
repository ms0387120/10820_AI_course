{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 862,
     "status": "ok",
     "timestamp": 1586090841848,
     "user": {
      "displayName": "廖柄淦",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZP21bMdjnp7AGGchu-PjXO1U_qXi0fI574q6H=s64",
      "userId": "05650689681420335783"
     },
     "user_tz": -480
    },
    "id": "8RuGapBJKLOP",
    "outputId": "44564467-9ae3-44fa-b141-1b50ab1dc9f1"
   },
   "outputs": [],
   "source": [
    "#Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2510,
     "status": "ok",
     "timestamp": 1586090846577,
     "user": {
      "displayName": "廖柄淦",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZP21bMdjnp7AGGchu-PjXO1U_qXi0fI574q6H=s64",
      "userId": "05650689681420335783"
     },
     "user_tz": -480
    },
    "id": "j7VTgxmaKMQY",
    "outputId": "fc1e1f6c-2d0b-4ede-eea8-b7fa058831d6"
   },
   "outputs": [],
   "source": [
    "#View the content of Google Drive\n",
    "!ls /content/gdrive/My\\ Drive/TA/1082"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3907,
     "status": "ok",
     "timestamp": 1586090850966,
     "user": {
      "displayName": "廖柄淦",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZP21bMdjnp7AGGchu-PjXO1U_qXi0fI574q6H=s64",
      "userId": "05650689681420335783"
     },
     "user_tz": -480
    },
    "id": "Kwlx46-sJxSO",
    "outputId": "4cbf64ef-ce66-4374-bbb0-c2002360d337"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import package\n",
    "%tensorflow_version 1.x\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras_applications import resnext\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PWEc8RZpNpHv"
   },
   "source": [
    "# **ResNeXt50 model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 662,
     "status": "ok",
     "timestamp": 1586090852169,
     "user": {
      "displayName": "廖柄淦",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZP21bMdjnp7AGGchu-PjXO1U_qXi0fI574q6H=s64",
      "userId": "05650689681420335783"
     },
     "user_tz": -480
    },
    "id": "-f2mtdfzNy1x",
    "outputId": "de41b4f7-26c8-4d2e-8e93-16b207f8af73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13831,
     "status": "ok",
     "timestamp": 1586090868050,
     "user": {
      "displayName": "廖柄淦",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZP21bMdjnp7AGGchu-PjXO1U_qXi0fI574q6H=s64",
      "userId": "05650689681420335783"
     },
     "user_tz": -480
    },
    "id": "bqwE5bIkJ8Ty",
    "outputId": "8029fe76-1ba4-4692-a63a-cf64869081ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conv_base = resnext.ResNeXt50(include_top=False, weights = 'imagenet', input_shape=(224, 224, 3), backend = keras.backend, layers = keras.layers, models = keras.models, utils = keras.utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 632,
     "status": "ok",
     "timestamp": 1586090890178,
     "user": {
      "displayName": "廖柄淦",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZP21bMdjnp7AGGchu-PjXO1U_qXi0fI574q6H=s64",
      "userId": "05650689681420335783"
     },
     "user_tz": -480
    },
    "id": "3yWYKrYsVfN4",
    "outputId": "cca91d5d-f1ab-4812-a937-b697e3c66d0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnext50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9408        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 58, 58, 128)  0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (DepthwiseC (None, 56, 56, 512)  4608        conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 56, 56, 32, 4 0           conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_reduce (Lambda)  (None, 56, 56, 32, 4 0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 56, 56, 128)  0           conv2_block1_2_reduce[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 128)  512         reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 128)  0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16384       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  32768       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  32768       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 58, 58, 128)  0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (DepthwiseC (None, 56, 56, 512)  4608        conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 56, 56, 32, 4 0           conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_reduce (Lambda)  (None, 56, 56, 32, 4 0           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 56, 56, 128)  0           conv2_block2_2_reduce[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 128)  512         reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 128)  0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  32768       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  32768       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 58, 58, 128)  0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (DepthwiseC (None, 56, 56, 512)  4608        conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 56, 56, 32, 4 0           conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_reduce (Lambda)  (None, 56, 56, 32, 4 0           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 56, 56, 128)  0           conv2_block3_2_reduce[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 128)  512         reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 128)  0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  32768       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 56, 56, 256)  65536       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 56, 56, 256)  1024        conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 56, 56, 256)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 58, 58, 256)  0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (DepthwiseC (None, 28, 28, 2048) 18432       conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 28, 28, 32, 8 0           conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_reduce (Lambda)  (None, 28, 28, 32, 8 0           reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 28, 28, 256)  0           conv3_block1_2_reduce[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 256)  1024        reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 256)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131072      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  131072      conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 256)  131072      conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 256)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 30, 30, 256)  0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (DepthwiseC (None, 28, 28, 2048) 18432       conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 28, 28, 32, 8 0           conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_reduce (Lambda)  (None, 28, 28, 32, 8 0           reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 28, 28, 256)  0           conv3_block2_2_reduce[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 256)  1024        reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 256)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  131072      conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 256)  131072      conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 256)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 30, 30, 256)  0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (DepthwiseC (None, 28, 28, 2048) 18432       conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 28, 28, 32, 8 0           conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_reduce (Lambda)  (None, 28, 28, 32, 8 0           reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 28, 28, 256)  0           conv3_block3_2_reduce[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 256)  1024        reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 256)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  131072      conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 256)  131072      conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 256)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 30, 30, 256)  0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (DepthwiseC (None, 28, 28, 2048) 18432       conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 28, 28, 32, 8 0           conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_reduce (Lambda)  (None, 28, 28, 32, 8 0           reshape_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 28, 28, 256)  0           conv3_block4_2_reduce[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 256)  1024        reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 256)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  131072      conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 28, 28, 512)  262144      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 28, 28, 512)  2048        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 28, 28, 512)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 30, 30, 512)  0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (DepthwiseC (None, 14, 14, 8192) 73728       conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 14, 14, 32, 1 0           conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_reduce (Lambda)  (None, 14, 14, 32, 1 0           reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 14, 14, 512)  0           conv4_block1_2_reduce[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 512)  2048        reshape_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 512)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 512)  524288      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 512)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 16, 16, 512)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (DepthwiseC (None, 14, 14, 8192) 73728       conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 14, 14, 32, 1 0           conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_reduce (Lambda)  (None, 14, 14, 32, 1 0           reshape_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)            (None, 14, 14, 512)  0           conv4_block2_2_reduce[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 512)  2048        reshape_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 512)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 512)  524288      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 512)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 16, 16, 512)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (DepthwiseC (None, 14, 14, 8192) 73728       conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)            (None, 14, 14, 32, 1 0           conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_reduce (Lambda)  (None, 14, 14, 32, 1 0           reshape_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_20 (Reshape)            (None, 14, 14, 512)  0           conv4_block3_2_reduce[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 512)  2048        reshape_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 512)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 512)  524288      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 512)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 16, 16, 512)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (DepthwiseC (None, 14, 14, 8192) 73728       conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_21 (Reshape)            (None, 14, 14, 32, 1 0           conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_reduce (Lambda)  (None, 14, 14, 32, 1 0           reshape_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_22 (Reshape)            (None, 14, 14, 512)  0           conv4_block4_2_reduce[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 512)  2048        reshape_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 512)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 512)  524288      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 512)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 16, 16, 512)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (DepthwiseC (None, 14, 14, 8192) 73728       conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_23 (Reshape)            (None, 14, 14, 32, 1 0           conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_reduce (Lambda)  (None, 14, 14, 32, 1 0           reshape_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_24 (Reshape)            (None, 14, 14, 512)  0           conv4_block5_2_reduce[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 512)  2048        reshape_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 512)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 512)  524288      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 512)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 16, 16, 512)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (DepthwiseC (None, 14, 14, 8192) 73728       conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_25 (Reshape)            (None, 14, 14, 32, 1 0           conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_reduce (Lambda)  (None, 14, 14, 32, 1 0           reshape_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_26 (Reshape)            (None, 14, 14, 512)  0           conv4_block6_2_reduce[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 512)  2048        reshape_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 512)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 14, 14, 1024) 1048576     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 14, 14, 1024) 4096        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 14, 14, 1024) 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, 16, 16, 1024) 0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (DepthwiseC (None, 7, 7, 32768)  294912      conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_27 (Reshape)            (None, 7, 7, 32, 32, 0           conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_reduce (Lambda)  (None, 7, 7, 32, 32) 0           reshape_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_28 (Reshape)            (None, 7, 7, 1024)   0           conv5_block1_2_reduce[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 1024)   4096        reshape_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 1024)   0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2097152     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   2097152     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 1024)   2097152     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 1024)   4096        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 1024)   0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, 9, 9, 1024)   0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (DepthwiseC (None, 7, 7, 32768)  294912      conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_29 (Reshape)            (None, 7, 7, 32, 32, 0           conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_reduce (Lambda)  (None, 7, 7, 32, 32) 0           reshape_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_30 (Reshape)            (None, 7, 7, 1024)   0           conv5_block2_2_reduce[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 1024)   4096        reshape_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 1024)   0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   2097152     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 1024)   2097152     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 1024)   4096        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 1024)   0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, 9, 9, 1024)   0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (DepthwiseC (None, 7, 7, 32768)  294912      conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_31 (Reshape)            (None, 7, 7, 32, 32, 0           conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_reduce (Lambda)  (None, 7, 7, 32, 32) 0           reshape_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_32 (Reshape)            (None, 7, 7, 1024)   0           conv5_block3_2_reduce[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 1024)   4096        reshape_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 1024)   0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   2097152     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,048,128\n",
      "Trainable params: 22,979,904\n",
      "Non-trainable params: 68,224\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6298,
     "status": "ok",
     "timestamp": 1586090899567,
     "user": {
      "displayName": "廖柄淦",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZP21bMdjnp7AGGchu-PjXO1U_qXi0fI574q6H=s64",
      "userId": "05650689681420335783"
     },
     "user_tz": -480
    },
    "id": "B5w1fn54LHx2",
    "outputId": "dfbb959c-df0c-44a0-de27-c5ed767836df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnext50 (Model)            (None, 7, 7, 2048)        23048128  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               12845184  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 35,893,699\n",
      "Trainable params: 17,342,979\n",
      "Non-trainable params: 18,550,720\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Freeze all layers\n",
    "for layer in conv_base.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "#Make some layer be trainable\n",
    "conv_base.get_layer('conv5_block3_1_conv').trainable = True\n",
    "conv_base.get_layer('conv5_block3_1_bn').trainable = True\n",
    "conv_base.get_layer('conv5_block3_2_conv').trainable = True\n",
    "conv_base.get_layer('conv5_block3_2_bn').trainable = True\n",
    "conv_base.get_layer('conv5_block3_3_conv').trainable = True\n",
    "conv_base.get_layer('conv5_block3_3_bn').trainable = True\n",
    "\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(layers.Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 582,
     "status": "ok",
     "timestamp": 1586090903246,
     "user": {
      "displayName": "廖柄淦",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZP21bMdjnp7AGGchu-PjXO1U_qXi0fI574q6H=s64",
      "userId": "05650689681420335783"
     },
     "user_tz": -480
    },
    "id": "PYZy1wowMF1y",
    "outputId": "fdc6e1aa-d53a-4815-e98a-14736e0d6848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "opt = optimizers.SGD(lr=0.01, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IZnReEWeOAZD"
   },
   "source": [
    "# **Prepare dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25997,
     "status": "ok",
     "timestamp": 1586090931443,
     "user": {
      "displayName": "廖柄淦",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZP21bMdjnp7AGGchu-PjXO1U_qXi0fI574q6H=s64",
      "userId": "05650689681420335783"
     },
     "user_tz": -480
    },
    "id": "1PD6zZNUN_2T",
    "outputId": "f0dc3cdb-ac7d-4294-9384-06135a9d9c08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shape:  (5600, 224, 224, 3) (5600, 3)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('/content/gdrive/My Drive/TA/1082/mango_train_planet_data.npz')\n",
    "X, Y = data['arr_0'], data['arr_1']\n",
    "print('Loaded shape: ', X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2201,
     "status": "ok",
     "timestamp": 1586090933652,
     "user": {
      "displayName": "廖柄淦",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZP21bMdjnp7AGGchu-PjXO1U_qXi0fI574q6H=s64",
      "userId": "05650689681420335783"
     },
     "user_tz": -480
    },
    "id": "atHp7B9lN_4r",
    "outputId": "52fed564-c308-4ef1-e467-e5ddef3261f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4480, 224, 224, 3) (4480, 3) (1120, 224, 224, 3) (1120, 3)\n"
     ]
    }
   ],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L7d6_6c3N_68"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0, rotation_range=15, featurewise_center=True, horizontal_flip=True)\n",
    "train_datagen.mean = [0.485, 0.456, 0.406]\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0, featurewise_center=True)\n",
    "test_datagen.mean = [0.485, 0.456, 0.406]\n",
    "\n",
    "train_it = train_datagen.flow(trainX, trainY, batch_size=64)\n",
    "test_it = test_datagen.flow(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ZMFz_UVOQuB"
   },
   "source": [
    "# **Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tB6vt1U8N_9X"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "checkpoint = ModelCheckpoint('/content/gdrive/My Drive/TA/1082/TestCNN4_weights.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 961
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 800430,
     "status": "ok",
     "timestamp": 1586091731903,
     "user": {
      "displayName": "廖柄淦",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZP21bMdjnp7AGGchu-PjXO1U_qXi0fI574q6H=s64",
      "userId": "05650689681420335783"
     },
     "user_tz": -480
    },
    "id": "BPrNqzvuOX4J",
    "outputId": "9b83854c-c626-4407-f4d0-080d92f5c729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 79s 1s/step - loss: 0.5430 - acc: 0.7484 - val_loss: 0.8413 - val_acc: 0.6265\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.84135, saving model to /content/gdrive/My Drive/TA/1082/TestCNN4_weights.h5\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 63s 905ms/step - loss: 0.3621 - acc: 0.8338 - val_loss: 0.4420 - val_acc: 0.7875\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.84135 to 0.44200, saving model to /content/gdrive/My Drive/TA/1082/TestCNN4_weights.h5\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 65s 934ms/step - loss: 0.3186 - acc: 0.8631 - val_loss: 0.6582 - val_acc: 0.6955\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.44200\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 65s 928ms/step - loss: 0.2961 - acc: 0.8726 - val_loss: 0.9101 - val_acc: 0.6408\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.44200\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 65s 930ms/step - loss: 0.2838 - acc: 0.8757 - val_loss: 0.6845 - val_acc: 0.6789\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.44200\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 65s 935ms/step - loss: 0.2272 - acc: 0.9024 - val_loss: 0.5370 - val_acc: 0.7872\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.44200\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 65s 932ms/step - loss: 0.2158 - acc: 0.9083 - val_loss: 0.5252 - val_acc: 0.7625\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.44200\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 65s 926ms/step - loss: 0.1917 - acc: 0.9225 - val_loss: 0.7505 - val_acc: 0.7068\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.44200\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 65s 925ms/step - loss: 0.1569 - acc: 0.9344 - val_loss: 1.0003 - val_acc: 0.7092\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.44200\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 65s 924ms/step - loss: 0.1399 - acc: 0.9421 - val_loss: 0.7999 - val_acc: 0.7548\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.44200\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 65s 926ms/step - loss: 0.1442 - acc: 0.9446 - val_loss: 0.7991 - val_acc: 0.7223\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.44200\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 65s 926ms/step - loss: 0.1266 - acc: 0.9499 - val_loss: 0.6209 - val_acc: 0.7509\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.44200\n",
      "Epoch 00012: early stopping\n",
      "CPU times: user 16min 10s, sys: 55 s, total: 17min 5s\n",
      "Wall time: 13min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit_generator(train_it, steps_per_epoch=len(train_it), epochs=100, validation_data=test_it, validation_steps=len(test_it), callbacks=[checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "40xf-h7cPZqu"
   },
   "source": [
    "# **Save and draw**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "obrZknKoPW-x"
   },
   "outputs": [],
   "source": [
    "model.save('/content/gdrive/My Drive/TA/1082/TestCNN4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3623,
     "status": "ok",
     "timestamp": 1586091735543,
     "user": {
      "displayName": "廖柄淦",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZP21bMdjnp7AGGchu-PjXO1U_qXi0fI574q6H=s64",
      "userId": "05650689681420335783"
     },
     "user_tz": -480
    },
    "id": "hd3KWW3mPXSd",
    "outputId": "e1fe94a8-0426-486a-c048-3147b505e9e3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJThP9M45l+A80TvnXILzRO+ccwnu/wFD0KJfG23J5AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nn7ldIDNIDUkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(train_acc) + 1)\n",
    "\n",
    "plt.plot(epochs, train_acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('/content/gdrive/My Drive/TA/1082/ResNeXt50-accuracy.png')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, train_loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.savefig('/content/gdrive/My Drive/TA/1082/ResNeXt50-loss.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Th0-KpJBPmcD"
   },
   "source": [
    "# **Evaluate and predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5195,
     "status": "ok",
     "timestamp": 1586091903043,
     "user": {
      "displayName": "廖柄淦",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZP21bMdjnp7AGGchu-PjXO1U_qXi0fI574q6H=s64",
      "userId": "05650689681420335783"
     },
     "user_tz": -480
    },
    "id": "ub3hbvEFPXhe",
    "outputId": "3137cb95-8860-44af-d4ea-e3e4084a63a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shape:  (800, 224, 224, 3) (800, 3)\n"
     ]
    }
   ],
   "source": [
    "#Load dev dataset\n",
    "data = np.load('/content/gdrive/My Drive/TA/1082/mango_dev_planet_data.npz')\n",
    "X, Y = data['arr_0'], data['arr_1']\n",
    "print('Loaded shape: ', X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JaqVXAabPXot"
   },
   "outputs": [],
   "source": [
    "#Load model\n",
    "model = models.load_model('/content/gdrive/My Drive/TA/1082/TestCNN4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EKm5ptuVPXwv"
   },
   "outputs": [],
   "source": [
    "#Load model weights\n",
    "model.load_weights('/content/gdrive/My Drive/TA/1082/TestCNN4_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6789,
     "status": "ok",
     "timestamp": 1586091941845,
     "user": {
      "displayName": "廖柄淦",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZP21bMdjnp7AGGchu-PjXO1U_qXi0fI574q6H=s64",
      "userId": "05650689681420335783"
     },
     "user_tz": -480
    },
    "id": "L_JC2QrcPyTN",
    "outputId": "e460da49-e28f-47cd-cd1a-0c492a6577f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.34509805 0.3647059  0.3764706 ]\n",
      "   [0.3254902  0.34509805 0.35686275]\n",
      "   [0.32941177 0.34901962 0.36078432]\n",
      "   ...\n",
      "   [0.38039216 0.3137255  0.09411765]\n",
      "   [0.3882353  0.32156864 0.10196079]\n",
      "   [0.38431373 0.31764707 0.09803922]]\n",
      "\n",
      "  [[0.34117648 0.36078432 0.37254903]\n",
      "   [0.3254902  0.34509805 0.35686275]\n",
      "   [0.33333334 0.3529412  0.3647059 ]\n",
      "   ...\n",
      "   [0.4        0.30980393 0.09803922]\n",
      "   [0.40784314 0.31764707 0.10588235]\n",
      "   [0.39607844 0.30588236 0.09411765]]\n",
      "\n",
      "  [[0.32156864 0.3529412  0.36078432]\n",
      "   [0.31764707 0.34901962 0.35686275]\n",
      "   [0.29411766 0.3254902  0.33333334]\n",
      "   ...\n",
      "   [0.44705883 0.36078432 0.13333334]\n",
      "   [0.43529412 0.34901962 0.12156863]\n",
      "   [0.4117647  0.3254902  0.09803922]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.56078434 0.5411765  0.5294118 ]\n",
      "   [0.5686275  0.54901963 0.5372549 ]\n",
      "   [0.5764706  0.5568628  0.54509807]\n",
      "   ...\n",
      "   [0.5529412  0.654902   0.65882355]\n",
      "   [0.5294118  0.6313726  0.63529414]\n",
      "   [0.50980395 0.6117647  0.6156863 ]]\n",
      "\n",
      "  [[0.57254905 0.5372549  0.5176471 ]\n",
      "   [0.5921569  0.5529412  0.54509807]\n",
      "   [0.62352943 0.58431375 0.5882353 ]\n",
      "   ...\n",
      "   [0.50980395 0.6117647  0.6156863 ]\n",
      "   [0.49019608 0.5921569  0.59607846]\n",
      "   [0.4745098  0.5764706  0.5803922 ]]\n",
      "\n",
      "  [[0.5568628  0.52156866 0.4862745 ]\n",
      "   [0.56078434 0.5254902  0.49803922]\n",
      "   [0.5921569  0.5529412  0.54509807]\n",
      "   ...\n",
      "   [0.5019608  0.58431375 0.59607846]\n",
      "   [0.48235294 0.5647059  0.5764706 ]\n",
      "   [0.4745098  0.5568628  0.5686275 ]]]\n",
      "\n",
      "\n",
      " [[[0.45490196 0.33333334 0.45882353]\n",
      "   [0.49411765 0.37254903 0.49411765]\n",
      "   [0.5019608  0.37254903 0.4862745 ]\n",
      "   ...\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   [0.00784314 0.00784314 0.00784314]]\n",
      "\n",
      "  [[0.4117647  0.32156864 0.43529412]\n",
      "   [0.61960787 0.5176471  0.6313726 ]\n",
      "   [0.4862745  0.36862746 0.47843137]\n",
      "   ...\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   [0.00784314 0.00784314 0.00784314]]\n",
      "\n",
      "  [[0.4392157  0.36078432 0.47058824]\n",
      "   [0.54901963 0.42745098 0.54901963]\n",
      "   [0.50980395 0.35686275 0.47843137]\n",
      "   ...\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   [0.00784314 0.00784314 0.00784314]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.10980392 0.10588235 0.13725491]\n",
      "   [0.11372549 0.10980392 0.13333334]\n",
      "   [0.07450981 0.07058824 0.09019608]\n",
      "   ...\n",
      "   [0.6039216  0.5019608  0.54509807]\n",
      "   [0.6039216  0.5019608  0.54509807]\n",
      "   [0.60784316 0.5058824  0.54901963]]\n",
      "\n",
      "  [[0.10196079 0.09803922 0.12156863]\n",
      "   [0.01960784 0.01960784 0.02745098]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.6117647  0.50980395 0.5529412 ]\n",
      "   [0.6117647  0.50980395 0.5529412 ]\n",
      "   [0.60784316 0.5058824  0.54901963]]\n",
      "\n",
      "  [[0.         0.         0.01568628]\n",
      "   [0.         0.         0.00784314]\n",
      "   [0.00392157 0.00392157 0.        ]\n",
      "   ...\n",
      "   [0.61960787 0.5176471  0.56078434]\n",
      "   [0.61960787 0.5176471  0.56078434]\n",
      "   [0.6156863  0.5137255  0.5568628 ]]]\n",
      "\n",
      "\n",
      " [[[0.6509804  0.6392157  0.5803922 ]\n",
      "   [0.65882355 0.64705884 0.5882353 ]\n",
      "   [0.6509804  0.6392157  0.5803922 ]\n",
      "   ...\n",
      "   [0.7411765  0.73333335 0.68235296]\n",
      "   [0.73333335 0.7254902  0.6745098 ]\n",
      "   [0.7372549  0.7294118  0.6784314 ]]\n",
      "\n",
      "  [[0.65882355 0.64705884 0.5882353 ]\n",
      "   [0.654902   0.6431373  0.58431375]\n",
      "   [0.63529414 0.62352943 0.5647059 ]\n",
      "   ...\n",
      "   [0.74509805 0.7372549  0.6862745 ]\n",
      "   [0.73333335 0.7254902  0.6745098 ]\n",
      "   [0.7490196  0.7411765  0.6901961 ]]\n",
      "\n",
      "  [[0.654902   0.6431373  0.58431375]\n",
      "   [0.6509804  0.6392157  0.5803922 ]\n",
      "   [0.63529414 0.62352943 0.5647059 ]\n",
      "   ...\n",
      "   [0.73333335 0.7254902  0.6745098 ]\n",
      "   [0.7490196  0.7411765  0.6901961 ]\n",
      "   [0.7411765  0.73333335 0.68235296]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.13333334 0.5137255  0.83137256]\n",
      "   [0.11372549 0.5019608  0.81960785]\n",
      "   [0.07450981 0.47843137 0.7882353 ]\n",
      "   ...\n",
      "   [0.79607844 0.5764706  0.5254902 ]\n",
      "   [0.7764706  0.5568628  0.5058824 ]\n",
      "   [0.7647059  0.54509807 0.49411765]]\n",
      "\n",
      "  [[0.10980392 0.49019608 0.80784315]\n",
      "   [0.10196079 0.49019608 0.80784315]\n",
      "   [0.07058824 0.4745098  0.78431374]\n",
      "   ...\n",
      "   [0.7607843  0.5411765  0.49019608]\n",
      "   [0.7411765  0.52156866 0.47058824]\n",
      "   [0.7411765  0.52156866 0.47058824]]\n",
      "\n",
      "  [[0.09019608 0.47058824 0.7882353 ]\n",
      "   [0.08235294 0.47058824 0.7882353 ]\n",
      "   [0.09411765 0.49803922 0.80784315]\n",
      "   ...\n",
      "   [0.7647059  0.54509807 0.49411765]\n",
      "   [0.7372549  0.5176471  0.46666667]\n",
      "   [0.7019608  0.48235294 0.43137255]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.5568628  0.5764706  0.56078434]\n",
      "   [0.5764706  0.5921569  0.5882353 ]\n",
      "   [0.5921569  0.60784316 0.61960787]\n",
      "   ...\n",
      "   [0.58431375 0.5882353  0.6039216 ]\n",
      "   [0.5882353  0.5921569  0.60784316]\n",
      "   [0.57254905 0.5764706  0.5921569 ]]\n",
      "\n",
      "  [[0.5764706  0.59607846 0.5803922 ]\n",
      "   [0.58431375 0.6        0.59607846]\n",
      "   [0.5921569  0.60784316 0.61960787]\n",
      "   ...\n",
      "   [0.58431375 0.5882353  0.6039216 ]\n",
      "   [0.5803922  0.58431375 0.6       ]\n",
      "   [0.5647059  0.5686275  0.58431375]]\n",
      "\n",
      "  [[0.5803922  0.6156863  0.59607846]\n",
      "   [0.5882353  0.62352943 0.6117647 ]\n",
      "   [0.5882353  0.61960787 0.627451  ]\n",
      "   ...\n",
      "   [0.5921569  0.59607846 0.6117647 ]\n",
      "   [0.5764706  0.5803922  0.59607846]\n",
      "   [0.56078434 0.5647059  0.5803922 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.654902   0.2627451  0.4745098 ]\n",
      "   [0.6392157  0.24313726 0.47058824]\n",
      "   [0.6431373  0.24705882 0.48235294]\n",
      "   ...\n",
      "   [0.14117648 0.07843138 0.07843138]\n",
      "   [0.14117648 0.07843138 0.07843138]\n",
      "   [0.14901961 0.08627451 0.08627451]]\n",
      "\n",
      "  [[0.64705884 0.24313726 0.45882353]\n",
      "   [0.6666667  0.25882354 0.49019608]\n",
      "   [0.654902   0.24705882 0.4862745 ]\n",
      "   ...\n",
      "   [0.14509805 0.08235294 0.08235294]\n",
      "   [0.13333334 0.07058824 0.07058824]\n",
      "   [0.14509805 0.08235294 0.08235294]]\n",
      "\n",
      "  [[0.6039216  0.19215687 0.4117647 ]\n",
      "   [0.6509804  0.23921569 0.47058824]\n",
      "   [0.6666667  0.2509804  0.49411765]\n",
      "   ...\n",
      "   [0.14117648 0.07843138 0.07843138]\n",
      "   [0.14901961 0.08627451 0.08627451]\n",
      "   [0.14117648 0.07843138 0.07843138]]]\n",
      "\n",
      "\n",
      " [[[0.60784316 0.5882353  0.5647059 ]\n",
      "   [0.5686275  0.54901963 0.5254902 ]\n",
      "   [0.52156866 0.5019608  0.47843137]\n",
      "   ...\n",
      "   [0.69411767 0.24313726 0.27058825]\n",
      "   [0.72156864 0.26666668 0.2784314 ]\n",
      "   [0.7529412  0.28235295 0.2901961 ]]\n",
      "\n",
      "  [[0.6117647  0.5921569  0.5686275 ]\n",
      "   [0.5568628  0.5372549  0.5137255 ]\n",
      "   [0.49803922 0.47843137 0.45490196]\n",
      "   ...\n",
      "   [0.6901961  0.23921569 0.25882354]\n",
      "   [0.73333335 0.2784314  0.28235295]\n",
      "   [0.75686276 0.28627452 0.2901961 ]]\n",
      "\n",
      "  [[0.6        0.5803922  0.5568628 ]\n",
      "   [0.5411765  0.52156866 0.49803922]\n",
      "   [0.49411765 0.4745098  0.4509804 ]\n",
      "   ...\n",
      "   [0.7019608  0.2509804  0.2627451 ]\n",
      "   [0.7294118  0.27450982 0.27450982]\n",
      "   [0.7647059  0.29411766 0.2901961 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5921569  0.5921569  0.56078434]\n",
      "   [0.59607846 0.5921569  0.5764706 ]\n",
      "   [0.61960787 0.6156863  0.60784316]\n",
      "   ...\n",
      "   [0.8627451  0.627451   0.58431375]\n",
      "   [0.8745098  0.64705884 0.6       ]\n",
      "   [0.8666667  0.65882355 0.6039216 ]]\n",
      "\n",
      "  [[0.5686275  0.5686275  0.5372549 ]\n",
      "   [0.59607846 0.5921569  0.5764706 ]\n",
      "   [0.61960787 0.6156863  0.60784316]\n",
      "   ...\n",
      "   [0.85882354 0.62352943 0.5803922 ]\n",
      "   [0.8666667  0.6392157  0.5921569 ]\n",
      "   [0.8627451  0.654902   0.6       ]]\n",
      "\n",
      "  [[0.5568628  0.5568628  0.5254902 ]\n",
      "   [0.58431375 0.5803922  0.5647059 ]\n",
      "   [0.60784316 0.6039216  0.59607846]\n",
      "   ...\n",
      "   [0.8509804  0.6156863  0.57254905]\n",
      "   [0.8627451  0.63529414 0.5882353 ]\n",
      "   [0.8627451  0.654902   0.6       ]]]\n",
      "\n",
      "\n",
      " [[[0.78039217 0.7058824  0.6901961 ]\n",
      "   [0.8        0.72156864 0.7294118 ]\n",
      "   [0.8235294  0.74509805 0.7529412 ]\n",
      "   ...\n",
      "   [0.4862745  0.5254902  0.49019608]\n",
      "   [0.4745098  0.5137255  0.48235294]\n",
      "   [0.47058824 0.50980395 0.47843137]]\n",
      "\n",
      "  [[0.78431374 0.70980394 0.69411767]\n",
      "   [0.83137256 0.7529412  0.7607843 ]\n",
      "   [0.8117647  0.73333335 0.7411765 ]\n",
      "   ...\n",
      "   [0.4862745  0.5254902  0.49019608]\n",
      "   [0.4745098  0.5137255  0.48235294]\n",
      "   [0.45882353 0.49803922 0.46666667]]\n",
      "\n",
      "  [[0.80784315 0.73333335 0.7176471 ]\n",
      "   [0.8117647  0.73333335 0.7411765 ]\n",
      "   [0.80784315 0.7294118  0.7372549 ]\n",
      "   ...\n",
      "   [0.50980395 0.54901963 0.5137255 ]\n",
      "   [0.48235294 0.52156866 0.49019608]\n",
      "   [0.46666667 0.5058824  0.4745098 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.64705884 0.74509805 0.7607843 ]\n",
      "   [0.6627451  0.7372549  0.7607843 ]\n",
      "   [0.6431373  0.7176471  0.73333335]\n",
      "   ...\n",
      "   [0.5372549  0.5647059  0.53333336]\n",
      "   [0.5294118  0.5686275  0.5372549 ]\n",
      "   [0.5294118  0.5686275  0.5372549 ]]\n",
      "\n",
      "  [[0.64705884 0.74509805 0.7607843 ]\n",
      "   [0.6627451  0.7372549  0.7607843 ]\n",
      "   [0.64705884 0.72156864 0.7372549 ]\n",
      "   ...\n",
      "   [0.5254902  0.5529412  0.52156866]\n",
      "   [0.5254902  0.5647059  0.53333336]\n",
      "   [0.5294118  0.5686275  0.5372549 ]]\n",
      "\n",
      "  [[0.6509804  0.7490196  0.7647059 ]\n",
      "   [0.6627451  0.7372549  0.7607843 ]\n",
      "   [0.64705884 0.72156864 0.7372549 ]\n",
      "   ...\n",
      "   [0.53333336 0.56078434 0.5294118 ]\n",
      "   [0.5254902  0.5647059  0.53333336]\n",
      "   [0.52156866 0.56078434 0.5294118 ]]]]\n"
     ]
    }
   ],
   "source": [
    "#Rescale dev dataset\n",
    "X/=255.0\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8825,
     "status": "ok",
     "timestamp": 1586092361778,
     "user": {
      "displayName": "廖柄淦",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZP21bMdjnp7AGGchu-PjXO1U_qXi0fI574q6H=s64",
      "userId": "05650689681420335783"
     },
     "user_tz": -480
    },
    "id": "LNy33JEzPXbO",
    "outputId": "a32d9c41-1681-4592-cc9c-735705f1de6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 8s 10ms/step\n",
      "Loss = 0.46640, Acc = 0.78000\n"
     ]
    }
   ],
   "source": [
    "#Evaluate model\n",
    "loss, acc = model.evaluate(X, Y)\n",
    "print('Loss = %.5f, Acc = %.5f' % (loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8992,
     "status": "ok",
     "timestamp": 1586092391954,
     "user": {
      "displayName": "廖柄淦",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZP21bMdjnp7AGGchu-PjXO1U_qXi0fI574q6H=s64",
      "userId": "05650689681420335783"
     },
     "user_tz": -480
    },
    "id": "ms2h3UHePyVj",
    "outputId": "b8dd0009-e759-4620-e1e4-6931ab1b2fd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "[0 0 0 1 2 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 2 0 0 0 2 1 0 1 0 0 1 2 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 0 2 0 0 0 1 2 0 0 1 0 2 0 0 0 2 0 0 2 2 0 2 1 2 1 0 2\n",
      " 2 0 0 0 2 0 0 2 0 0 2 1 2 1 0 1 2 0 1 0 1 2 1 0 2 0 0 1 0 2 0 1 1 0 0 0 2\n",
      " 0 1 0 0 0 2 0 0 0 1 0 2 0 2 0 0 0 2 1 0 0 0 1 0 1 0 0 0 2 0 0 2 0 0 0 1 0\n",
      " 0 1 1 0 0 0 1 0 0 0 2 1 2 0 0 0 2 2 0 2 0 2 1 1 2 2 2 1 0 1 0 0 2 1 1 2 0\n",
      " 2 0 1 2 1 0 2 0 0 2 0 0 2 2 0 2 1 0 0 0 0 0 0 2 1 2 0 0 0 0 2 0 1 1 1 0 1\n",
      " 0 1 0 1 1 0 1 1 0 0 1 1 0 0 2 0 1 0 1 2 1 0 0 0 1 1 1 1 1 0 2 2 2 0 1 1 2\n",
      " 2 2 0 1 0 2 1 1 0 0 1 2 0 0 0 0 1 2 0 1 0 0 0 0 2 1 0 1 2 1 0 2 0 2 2 0 2\n",
      " 1 1 1 2 2 0 2 0 2 2 1 2 2 2 2 0 2 1 0 0 0 1 1 0 0 1 1 1 2 0 1 1 0 2 1 0 2\n",
      " 0 2 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 2 1 0 0 0 0 0 1 1 0 1 0 0\n",
      " 2 2 0 0 0 1 0 2 0 2 0 0 0 1 1 2 1 2 0 2 2 2 0 2 2 0 0 2 0 0 0 0 2 0 0 2 0\n",
      " 0 2 0 0 2 1 0 0 1 0 2 1 0 0 0 0 0 0 2 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1 0 1 0\n",
      " 0 0 0 0 0 1 2 2 1 2 0 0 0 1 0 1 0 0 2 0 0 0 1 0 0 0 1 2 2 1 0 1 2 0 1 1 0\n",
      " 0 0 0 2 0 0 1 2 2 2 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 2 0 0 0 0 2 1\n",
      " 0 1 1 0 1 2 1 1 0 2 2 1 0 1 1 2 2 0 1 0 1 0 0 0 1 1 0 2 0 1 0 2 1 0 1 0 2\n",
      " 2 0 0 0 0 2 1 0 0 0 1 0 0 1 0 1 1 0 0 2 0 0 1 0 1 2 1 1 0 1 0 0 2 1 2 0 0\n",
      " 0 0 0 1 2 0 0 1 2 2 0 2 1 0 0 2 2 1 0 1 0 0 2 1 1 0 0 0 0 0 0 2 0 0 0 0 0\n",
      " 0 2 1 0 0 1 1 2 0 0 0 0 1 0 1 0 0 0 1 0 2 2 2 2 2 1 0 1 2 0 0 0 0 2 1 1 2\n",
      " 0 0 2 0 2 2 1 0 0 0 2 0 0 0 1 2 2 1 0 0 0 0 1 1 0 2 0 0 1 2 0 2 1 0 0 0 0\n",
      " 0 0 2 1 0 0 1 0 0 0 1 0 0 2 0 2 0 0 1 1 2 2 0 0 1 0 1 2 0 0 2 1 2 1 1 2 0\n",
      " 1 1 2 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 2 0 0 1 0 1 0 0 1 0 0 1 2 0 0 0\n",
      " 1 2 2 1 0 2 1 1 0 2 2 1 1 1 2 0 1 0 1 0 2 0 2]\n"
     ]
    }
   ],
   "source": [
    "#Predict result\n",
    "y_predict = model.predict_classes(X)\n",
    "print(len(y_predict))\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 692,
     "status": "ok",
     "timestamp": 1586092394895,
     "user": {
      "displayName": "廖柄淦",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZP21bMdjnp7AGGchu-PjXO1U_qXi0fI574q6H=s64",
      "userId": "05650689681420335783"
     },
     "user_tz": -480
    },
    "id": "FMJFyYdePyXm",
    "outputId": "f144924f-6aba-49a7-e622-a4614837dd12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 2 1 2 0 1 0 0 1 2 1 2 1 1 0 0 1 0 0 2 0 1 0 2 2 1 1 1 0 2 2 0 0 0\n",
      " 0 0 0 1 2 0 2 2 2 1 0 2 0 1 1 1 2 2 0 1 0 2 0 1 1 2 0 1 2 2 0 2 1 2 1 1 2\n",
      " 2 2 1 0 2 0 0 2 1 1 2 2 2 2 0 1 2 2 1 2 2 2 1 0 2 2 2 1 1 2 1 1 1 1 1 2 2\n",
      " 0 1 0 0 2 2 0 2 0 1 0 2 1 2 1 0 1 2 1 0 0 0 1 0 2 1 1 0 2 0 1 2 0 0 0 2 1\n",
      " 1 1 1 1 1 1 1 1 1 0 2 1 2 1 0 1 2 2 1 2 0 2 1 2 2 2 2 1 0 0 0 1 2 2 0 2 1\n",
      " 2 0 0 2 1 2 2 1 1 2 1 0 2 1 0 2 2 1 0 1 2 0 1 2 2 2 1 1 2 0 2 1 2 1 1 0 1\n",
      " 1 1 1 1 0 0 1 1 0 2 1 1 0 1 2 0 2 0 1 2 2 0 1 0 2 2 2 1 0 1 2 2 2 1 1 1 2\n",
      " 2 2 1 1 0 2 1 2 0 1 2 2 1 1 1 1 2 2 0 2 0 1 0 0 1 1 1 1 2 1 2 2 0 2 2 1 1\n",
      " 0 1 1 2 2 0 2 0 2 2 1 2 1 2 2 0 2 1 0 2 0 1 1 0 0 1 1 2 2 1 1 1 0 2 1 1 2\n",
      " 0 2 1 1 2 1 1 1 2 0 2 0 0 0 0 0 1 2 1 2 0 1 0 1 2 1 0 0 1 0 0 2 1 1 1 1 1\n",
      " 2 2 1 2 0 2 1 2 0 2 0 1 0 1 1 2 1 1 0 2 2 2 1 2 1 0 1 1 1 1 0 0 2 1 0 2 1\n",
      " 1 2 0 0 2 1 0 1 1 1 2 2 1 1 0 0 2 0 2 1 1 1 2 2 0 2 0 1 2 2 1 1 0 1 0 1 0\n",
      " 0 1 0 1 1 1 2 2 2 2 0 0 0 1 0 2 2 1 2 2 0 1 1 0 1 0 1 2 2 1 0 1 2 1 1 1 0\n",
      " 0 0 0 1 2 1 1 2 2 1 2 1 1 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 1 1 2 1 0 0 2 2 1\n",
      " 0 1 0 1 2 2 2 1 1 2 2 1 2 1 1 1 2 0 1 0 2 0 0 0 2 1 0 2 0 1 0 2 1 0 2 0 2\n",
      " 1 0 0 0 0 2 1 1 1 0 1 0 0 1 0 1 1 0 1 2 0 1 1 1 1 2 1 1 1 1 0 1 2 2 2 0 0\n",
      " 1 1 0 1 2 2 0 1 2 2 1 2 1 0 0 2 2 1 2 2 2 2 2 0 2 1 1 1 1 0 0 2 0 0 0 0 0\n",
      " 0 2 1 1 0 1 2 2 0 0 0 2 1 1 0 0 0 1 0 1 2 2 2 1 2 1 1 2 2 1 1 2 1 2 1 2 2\n",
      " 0 0 2 0 2 2 2 1 0 0 2 0 0 0 1 2 2 1 1 0 0 1 2 1 0 2 2 0 2 1 0 2 2 0 0 1 0\n",
      " 0 2 2 1 1 0 2 0 0 0 1 1 0 2 0 2 0 1 1 1 2 2 0 2 1 0 2 2 1 0 2 1 2 1 2 2 0\n",
      " 1 1 2 2 1 1 0 0 1 0 1 2 0 0 0 1 1 0 1 2 0 1 0 0 2 0 1 0 0 1 1 1 2 2 0 0 1\n",
      " 2 2 2 1 0 2 2 0 0 2 2 1 2 2 1 1 1 0 1 0 2 0 2]\n"
     ]
    }
   ],
   "source": [
    "#dev image label\n",
    "Y_cat = Y.argmax(axis=-1)\n",
    "print(Y_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ghFtEC2kP_UH"
   },
   "source": [
    "# **Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 718,
     "status": "ok",
     "timestamp": 1586092398257,
     "user": {
      "displayName": "廖柄淦",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZP21bMdjnp7AGGchu-PjXO1U_qXi0fI574q6H=s64",
      "userId": "05650689681420335783"
     },
     "user_tz": -480
    },
    "id": "FbqGItjVP9IX",
    "outputId": "5d20dc44-c507-40bf-825c-083ea714f652"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>148</td>\n",
       "      <td>130</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>66</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prediction    0    1    2\n",
       "labels                   \n",
       "0           232   11    0\n",
       "1           148  130   15\n",
       "2            39   66  159"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix by pandas\n",
    "pd.crosstab(Y_cat, y_predict, rownames=['labels'], colnames=['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 629,
     "status": "ok",
     "timestamp": 1586092401664,
     "user": {
      "displayName": "廖柄淦",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZP21bMdjnp7AGGchu-PjXO1U_qXi0fI574q6H=s64",
      "userId": "05650689681420335783"
     },
     "user_tz": -480
    },
    "id": "omYBIJCJP9PV",
    "outputId": "40a72f38-9879-4919-c7e3-71893de4f2af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[232  11   0]\n",
      " [148 130  15]\n",
      " [ 39  66 159]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix by sklearn\n",
    "c = confusion_matrix(Y_cat, y_predict)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 822,
     "status": "ok",
     "timestamp": 1586092404817,
     "user": {
      "displayName": "廖柄淦",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZP21bMdjnp7AGGchu-PjXO1U_qXi0fI574q6H=s64",
      "userId": "05650689681420335783"
     },
     "user_tz": -480
    },
    "id": "OOkY6JyVP9Wu",
    "outputId": "059b3a90-ce29-45eb-e818-950bc1ca93de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.55      0.95      0.70       243\n",
      "           B       0.63      0.44      0.52       293\n",
      "           C       0.91      0.60      0.73       264\n",
      "\n",
      "    accuracy                           0.65       800\n",
      "   macro avg       0.70      0.67      0.65       800\n",
      "weighted avg       0.70      0.65      0.64       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Precison, recall and f1-score\n",
    "print(classification_report(Y_cat, y_predict, target_names=['A', 'B', 'C']))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPtWVrXDx26O+8qt58BF6FD",
   "collapsed_sections": [],
   "name": "CNN_ResNeXt-50.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
